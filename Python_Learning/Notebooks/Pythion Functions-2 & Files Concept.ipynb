{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33afb7cb",
   "metadata": {},
   "source": [
    "# 1) Decorators:- This is important topic we can say intermediately imprtant topic based on the interest we can move forward.\n",
    "## NOTE:Decoratores are very useful for product based companies.Decorators are helpful in building libraries and ML modules inorder to support or make our code compatible with the hardware and make our code lite and efficient to execute in our hardware system.Decoraters are like wrappers that decorates our code and makes additional functionality at background and make compatible with our hardware either CPU or GPU.\n",
    "## Using decorators we make abstractions and make users to write their code easily and with less effort by our library which was built using decorators(Example flask,Django,numpy etc,...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4304abd",
   "metadata": {},
   "source": [
    "# NOTE:  Mostly we write logic related to hardware in decorators in c/c++ and integrate with python or we write in c/c++ like a headers and import it in our decorators and utilizes that code with python wrapper.\n",
    "## It means In general, it is common to write low-level code related to hardware or performance critical tasks in C/C++ because these languages offer more control over low-level details such as memory management and optimization. However, using C/C++ code in Python can be challenging, as the two languages have different syntax and runtime environments.\n",
    "## One way to integrate C/C++ code with Python is to write a wrapper in Python that calls C/C++ code using the ctypes or Cython libraries. This involves defining the C/C++ function in a header file, compiling it into a shared library, and then loading the library and calling the function from Python. This approach allows you to write the core functionality in C/C++ for performance reasons, while still being able to call it from Python.\n",
    "## Another approach is to use a C/C++ library that has already been wrapped in Python using a library such as Boost.Python or Pybind11. These libraries provide tools for exposing C++ classes and functions to Python and can simplify the process of integrating C/C++ code with Python.\n",
    "## As for decorators specifically, it is possible to use C/C++ code in a Python decorator, but this approach would likely involve writing a Python extension module in C/C++ and then importing it into the Python script that defines the decorator. This approach would be more complex and require more low-level knowledge of both Python and C/C++.\n",
    "## Overall decorators are used to make our code easier and efficient in background with hardware compatibility and making users to write the code without much efforts and extra code to their code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In Python, a decorator is a special type of function that can modify or extend. \n",
    "The behavior of another function without changing its source code. \n",
    "Decorators are used by adding the @decorator_name syntax on top of the function to be modified.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87624e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"*args and **kargs\" will be used bcs a decorator must be a general purpose so we must write params as a syntax rule.\n",
    "#We should maintain it as an optiuonal arguments for a general purpose decorators.We mostly use general decorators.\n",
    "#Main Syntax or Structure --> \n",
    "#         def decorator_name(original_function):\n",
    "#                   def new_function(*args, **kwargs):\n",
    "#                      Logic or Add functionality here --> Here we write our \"main logic\" what we want to implement.what we want to get or achieve from decorator.\n",
    "#                         return original_function(*args, **kwargs)\n",
    "#                    return new_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54e5212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Syntax -->def decorator_name(func):\n",
    "#                        def wrapper(*args, **kwargs):\n",
    "#                            # Do some actions before calling the decorated function\n",
    "#                            result = func(*args, **kwargs)\n",
    "#                            # Do some actions after calling the decorated function\n",
    "#                            return result\n",
    "#                        return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "From above Syntax code depicts--> The decorator_name function takes a function func as an argument, and returns another function called wrapper.\n",
    "The wrapper function takes any number of positional and keyword arguments (*args and **kwargs), \n",
    "performs some actions before and after calling the decorated function, and finally returns its result.\n",
    "To use the decorator, you simply apply it to the function you want to modify, using the @ syntax. For example:\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78af256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syntax -->@decorator_name \n",
    "#           def my_function(x, y):\n",
    "              # Do something\n",
    "#             return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c1b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "From above Syntax code depicts--> This will modify the behavior of my_function using the decorator_name decorator. When my_function is called,\n",
    "It will actually call the wrapper function defined in the decorator, which will in turn call the original my_function,\n",
    "with the provided arguments, and perform some actions before and after the call.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103dc4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 1 --> decorator which caluclates the timecomplexity of our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ca3957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time #Inorder to write decorator of timecomplexity we need to import \"time\" module from python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58e86b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1676796548.730318"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfb20069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 1\n",
    "def timeComplexity(func): #Basically decorator takes the function as an input.\n",
    "    \n",
    "# Here we used parameters like \"*args and **kargs\" these are optional parameters it takes any no.of.parameters.\n",
    "#if our function have parameters then only it will take the parameters.for every decorator we must provide \"*args and **kargs\".\n",
    "\n",
    "    def getParams(*args,**kargs): #It is sub function of decorator here \"getParams\" it takes any no.of.parameters which checks the parameters for our function which we are sending as an input and it takes those parameters\n",
    "        #### LOGIC ####\n",
    "        first = time.time() #It caluclates the present time Here.It will caluclate time before executing the function.\n",
    "        print(\"Before Function...!\") #Instead of \"print\" here we can write anything.In realtime we can setup hardware or related to hardware or anything we can write here.Then our function will work on this particular environment.\n",
    "        value = func(*args, **kargs) #Here it will execute the function(Here it will call greeting function)\n",
    "        second = time.time() #It caluclates the present time Here.It will caluclate time after executing the function.\n",
    "        print(\"After Function...!\") #Instead or \"print\" here we can write anything.suppose In real time After executing function what are the resources or hardware holds or created we need to release it something like that after function.\n",
    "        latency = second - first\n",
    "        print(f\"Latency is {latency}\")\n",
    "    return getParams\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7c6f81",
   "metadata": {},
   "source": [
    "## For Example  we have a decorator function like \"@tf.fuction\" which is related to tensorflow library  if we write a function in a normal way it will run in another way and if we run a function using \"@tf.function\" it will run in another way(it means this function which we written will try to convert it into parallely. This \"@tf.function\" decorater makes our total function to become parallelize and make compatible to our hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89eaf90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeComplexity #This decorator works as a wrapper from backend and use it for normal function and not make user to trouble then it is called decorator.\n",
    "def greeting(): #Here before it execute the greetings function or original_function.It will automatically executes or performs decorator funcion.\n",
    "    print(\"I am a Greeting Function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7f5a24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Function...!\n",
      "I am a Greeting Function\n",
      "After Function...!\n",
      "Latency is 0.0009970664978027344\n"
     ]
    }
   ],
   "source": [
    "greetings() #calling the function.Below the latency is either seconds or a milliseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe6493db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 2\n",
    "@timeComplexity\n",
    "def abc():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9759c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Function...!\n",
      "After Function...!\n",
      "Latency is 0.0\n"
     ]
    }
   ],
   "source": [
    "abc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8141922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 3\n",
    "@timeComplexity # --> This works only to this function.If want to execute function we need to add the decorater to that particular function only.\n",
    "def greeting(): \n",
    "    def abcd(): #This function is has only local scope to this particular function \"greetings()\" only.This function also run as function in a timeComplexity but it doesn't work as a separate decorator.\n",
    "        pass\n",
    "    print(\"I am a Greeting Function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cdca3227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Function...!\n",
      "I am a Greeting Function\n",
      "After Function...!\n",
      "Latency is 0.0009970664978027344\n"
     ]
    }
   ],
   "source": [
    "greeting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8355c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 4\n",
    "@timeComplexity # --> This works only to this function.If want to execute function we need to add the decorater to that particular function only.\n",
    "def greetin(): \n",
    "#    @timeComplexity\n",
    "    def abcd(): #This function is has only local scope to this particular function \"greetings()\" only.This function also run as function in a timeComplexity but it doesn't work as a separate decorator.\n",
    "        pass\n",
    "    abcd() #We can only call this function inside it we don't have chance to write it and call from outside.\n",
    "    print(\"I am a Greeting Function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "688244f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Function...!\n",
      "Before Function...!\n",
      "After Function...!\n",
      "Latency is 0.0\n",
      "I am a Greeting Function\n",
      "After Function...!\n",
      "Latency is 0.0\n"
     ]
    }
   ],
   "source": [
    "greetin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18ae67f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 5\n",
    "@timeComplexity # --> This works only to this function.If want to execute function we need to add the decorater to that particular function only.\n",
    "def greeting(): \n",
    "#    @timeComplexity --> By default it won't add into decorator for any function until we explicitly define it.\n",
    "    def abcd(): #This function is has only local scope to this particular function \"greetings()\" only.This function also run as function in a timeComplexity but it doesn't work as a separate decorator.\n",
    "        pass\n",
    "    abcd() #We can only call this function inside it we don't have chance to write it and call from outside.\n",
    "    print(\"I am a Greeting Function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e60aa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Function...!\n",
      "I am a Greeting Function\n",
      "After Function...!\n",
      "Latency is 0.0\n"
     ]
    }
   ],
   "source": [
    "greeting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff63abc",
   "metadata": {},
   "source": [
    "# 2) Generators:- \n",
    "# --> We use it basically more bcs This concept or function related to our data science which are called generators.We use generators mostly in data preparation and in data generation.Generators are used in space management which is highly performance in dealing large data like in \"TB's\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef524bf1",
   "metadata": {},
   "source": [
    "## In Python, a generator is a special type of function that generates a sequence of values, one at a time, instead of returning a single value. Generators are often used in data science and machine learning because they allow you to work with large datasets without having to load all the data into memory at once. \n",
    "## Generators are especially useful when working with very large datasets that cannot fit into memory. Instead of loading the entire dataset into memory, a generator allows you to iterate over the data one batch at a time. This is sometimes referred to as \"lazy evaluation\" or \"lazy loading\".\n",
    "## For example, let's say you have a large CSV file with millions of rows. Instead of reading the entire file into memory at once, you can use a generator to read the file line by line. This allows you to process each line of the file one at a time, without having to load the entire file into memory.\n",
    "## Generators are also useful when working with data streams, such as live sensor data or streaming video. In these cases, data is constantly being generated, and it may not be possible to load all of the data into memory at once. A generator can be used to process the data as it is generated, without having to wait for the entire data stream to finish.\n",
    "## In summary, generators are useful in data science and machine learning because they allow you to work with large datasets and data streams without having to load all of the data into memory at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34ec47e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "def generateEven(L): #If there are very larege data  we get the actual difference.As an example Here we taken small example data.\n",
    "    for i in L:\n",
    "        if i % 2 == 0:\n",
    "            yield i #Here \"yield\" is used to move the data from ram to external storage like disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e3074be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 6, 8]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(generateEven([12,3,5,6,7,8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6d376c",
   "metadata": {},
   "source": [
    "# 3) Files: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da118988",
   "metadata": {},
   "source": [
    "## NOTE: We have separate libraries inorder to handle each file system format like \"json\" file has json library to handle(like data conversion,processing etc..), while we handle \"Xml\" files we have xml libraries, while handling \"csv\" we have pandas as a good library.for every file format we have a specific libraries.In older generation there is no handling libraries they used to perform or manipulate with strings it's an old we no need learn it instead we learn json library or pandas library to make easy to handle data or manipulate data or process data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b45cf6",
   "metadata": {},
   "source": [
    "# -->In data science We use files mostly in manipulating 60 to 70% of \"Json\" Files which is related with dictionaries to relate with dictionaries.Another 10% are manifest Files which are related to the cloud we use it in auomation.\"manifest files\" are also related like json files.json and manifest files are mostly we use here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37854c89",
   "metadata": {},
   "source": [
    "# =>Json File: These json files are It's very very important.We use json files like in loggin etc... it has unlimited uses.we can use it in anywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ae0a33",
   "metadata": {},
   "source": [
    "## NOTE: JSON can be 2 types:1)Json will be a  dictionary and 2)Json will also be a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a3af3079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\\n#Here we have only difference between python and json boolean type it has \"True or False\" while in json file it has \"true or false\"\\n    \"key\":value -- It\\'s value can be any data type or anything either it can be a string or  number or it can be list of some values etc..\\n     -------\\n     -------\\n     -------\\n     -------\\n}\\n\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Syntax of \"json\" as a dictionary.\n",
    "#Syntax of Json File\n",
    "'''\n",
    "{\n",
    "\n",
    "    \"key\":value -- It's value can be any data type or anything either it can be a string or  number or it can be list of some values etc..\n",
    "     -------\n",
    "     -------\n",
    "     -------\n",
    "     -------\n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb561c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syntax of \"json\" as a list.\n",
    "#It can also be treated as a json file.\n",
    "'''\n",
    "[\n",
    "    \n",
    "    {\n",
    "    \n",
    "        \"key\":value\n",
    "        -----------\n",
    "        -----------\n",
    "        -----------\n",
    "        -----------\n",
    "    \n",
    "    }\n",
    "    \n",
    "]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee153849",
   "metadata": {},
   "source": [
    " ## NOTE:-Here we have only difference between python and json is boolean type it has \"True or False\" in python while in json file it has \"true or false\"  all these things to be  handled  inorder to process the data.Suppose Inorder to send the capital T in True or capital F in False which is in our dictionary in our python code to \"json\" file it need to be process according to compatible with the json file.\n",
    " ## For this we need not to be process inorder to do all these things we have a library called \"json\" library we need to import it in our code and implement it inorder to send our code into \"json\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e63d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "51ab4cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's say we have student data\n",
    "students = [{\"name\":\"Saikiran\",\"Age\":23,\"isStudent\":False},{\"name\":\"Savinay\",\"Age\":17,\"isStudent\":True}] #This data is now temporarily in file buffer in RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eb8cde0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Saikiran', 'Age': 23, 'isStudent': False},\n",
       " {'name': 'Savinay', 'Age': 17, 'isStudent': True}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is our dictionary.My intention is to store this dictionary into json file.\n",
    "#Here we are dealing with json files not a normal files.\n",
    "#Here we can't dump it directly if we dump directly these \"True or False\" also we need to send like a string.\n",
    "#So,we don't have chance to save our datatype here.This \"json\" will parse all these data or every element in dictionary.\n",
    "#Parse means it iterate through every element and checks its datatype and uploads it intojson file according to its datatype.\n",
    "#Suppose if we use \"file.write()\" there is no data conversions we need to append like a string there is no parsing in it.\n",
    "#This json library will provide us parsing inorder to append it into json according to its data type which makes compatible with json file.\n",
    "\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc5859",
   "metadata": {},
   "source": [
    "##  NOTE: Throughout this course we mostly use \"json\" files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c8569b",
   "metadata": {},
   "source": [
    "## (1) Writing into \"json\" file: \n",
    "## NOTE: Here if we open a file in writing mode there is no problem Bcs if a file a file doesn't exists it will create new file or if there is a file it will override on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "01109a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inorder to store the dictionary into json we first need to \"open\" the file as below:\n",
    "#When we opened the file in writing mode \"sample.json\" file will be created in our disc od current working directory if we don't specify any path.\n",
    "#Or else If we give any path then it will be created in that path.After created the file that created file that is here \"sample.json\"\n",
    "#This file will be established a connection with the buffer in RAM this we call file buffer.This file buffer is connecting to the created file in Disc.\n",
    "\n",
    "file = open(\"sample.json\",\"w\") #Here \"sample.json\" is a file_name and \"w\" is a mode type like write or read or append modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5e2121a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function dump in module json:\n",
      "\n",
      "dump(obj, fp, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)\n",
      "    Serialize ``obj`` as a JSON formatted stream to ``fp`` (a\n",
      "    ``.write()``-supporting file-like object).\n",
      "    \n",
      "    If ``skipkeys`` is true then ``dict`` keys that are not basic types\n",
      "    (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n",
      "    instead of raising a ``TypeError``.\n",
      "    \n",
      "    If ``ensure_ascii`` is false, then the strings written to ``fp`` can\n",
      "    contain non-ASCII characters if they appear in strings contained in\n",
      "    ``obj``. Otherwise, all such characters are escaped in JSON strings.\n",
      "    \n",
      "    If ``check_circular`` is false, then the circular reference check\n",
      "    for container types will be skipped and a circular reference will\n",
      "    result in an ``RecursionError`` (or worse).\n",
      "    \n",
      "    If ``allow_nan`` is false, then it will be a ``ValueError`` to\n",
      "    serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``)\n",
      "    in strict compliance of the JSON specification, instead of using the\n",
      "    JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n",
      "    \n",
      "    If ``indent`` is a non-negative integer, then JSON array elements and\n",
      "    object members will be pretty-printed with that indent level. An indent\n",
      "    level of 0 will only insert newlines. ``None`` is the most compact\n",
      "    representation.\n",
      "    \n",
      "    If specified, ``separators`` should be an ``(item_separator, key_separator)``\n",
      "    tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n",
      "    ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n",
      "    you should specify ``(',', ':')`` to eliminate whitespace.\n",
      "    \n",
      "    ``default(obj)`` is a function that should return a serializable version\n",
      "    of obj or raise TypeError. The default simply raises TypeError.\n",
      "    \n",
      "    If *sort_keys* is true (default: ``False``), then the output of\n",
      "    dictionaries will be sorted by key.\n",
      "    \n",
      "    To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n",
      "    ``.default()`` method to serialize additional types), specify it with\n",
      "    the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(json.dump) #Here \"json.dump()\" is a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e38ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are going to \"dump\" our data into the created file in Disc from file buffer in RAM.\n",
    "#Syntax of dump --> json.dump(data_object,destination_file)\n",
    "\n",
    "json.dump(students,file) #Here we By using \"json\" library we are dumping or riding our dictionary into the file we created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ca1bdc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also dump or ride our dictionary using \"file.write()\" but we can't do for \"json\" files.\n",
    "#Bcs As we discussed before \"json\" has specifically another data type as we said only one that is boolean data type.\n",
    "#\"json\" file it will treat it as an another way Whereas the \"true\" is different in our code as \"True\" but in json it will be \"true\".\n",
    "#Suppose if we have any boolean data type in our dictionary like \"True or False\".\n",
    "#Here when we use this the connection will be closed between RAM and file in disc.\n",
    "#It wil store temporarily until we  close the file.After we close it become persistent.This closing method also called checkpointing.\n",
    "#Then the data buffer which is in RAM will be stored in our actual file.After closing only the data will be stored in actual file from RAM.\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "55868842",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"sample.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "daeadf01",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Here if we write like this it will not take anything except \"string\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudents\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not list"
     ]
    }
   ],
   "source": [
    "#Here if we write like this it will not take anything except \"string\"\n",
    "file.write(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3a313d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here the data will be stored as a \"string\" not as a dictionary in normal files.\n",
    "#Here Normal file opeartions are only deals with strings.For this it doesn't care about data types.\n",
    "#if we write in any data type(like strings,integer etc..) it will treat like only as a strings.\n",
    "#Here \"students\" is a \"list\" or else \"dictionary\"  If we give this \"list\" directly it throws error as argument must be \"string(str)\".It will only take string parameters.\n",
    "file.write(str(students)) #Here we passed data  as a String.The output below is the no.of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "97dda1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f61458f",
   "metadata": {},
   "source": [
    "## (2) Reading from \"json\" file:\n",
    "## NOTE:When we open a file by mistake or if we don't  know that file exists or not it get's exception or error as \"file not found\" in reading mode. Here we are using notebook for our experiment purpose suppose if we write a project in scripts in vscode or In some IDE if we get such exceptions we need to handle it using \"try and except\" In order to avoid system or code or program crasha.Exception handling is also useful in handling these type of errors or exceptions in \"automation systems\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "888c2e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here the persistent data storage which is in disc will be exist thereitself and \n",
    "#The data which is in persistent data storage will be created as a buffer and that buffer will comes into our RAM.\n",
    "#So,now if I want to process or to do anything I can do process the data which is in RAM only.\n",
    "#Bcs the computer has only relation with RAM not with a disc.\n",
    "file = open(\"sample.json\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c6bf2556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a problem...!\n"
     ]
    }
   ],
   "source": [
    "#In such type of connections we always maintain \"try and except\" to handle exceptions.\n",
    "try:\n",
    "    file = open(\"sample2.json\",\"r\")\n",
    "except:\n",
    "#we need to write an automated or set alarm message or program in exception block.\n",
    "#Inorder to send message to developers or admins or users as an data engineer.\n",
    "#when try to build large automation piplelines or data.\n",
    "    print(\"There is a problem...!\") \n",
    "#It always good practice to write \"finally\" block and also safer to avoid unknown access or usages.\n",
    "finally:  #finally is used to close any \"socket\" connections like database or file connections or resource release or whatever the connections will be opened  are closed here.\n",
    "    file.close()\n",
    "else:\n",
    "    pass\n",
    "    ## else will be executed if there is no error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e9e777d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load in module json:\n",
      "\n",
      "load(fp, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)\n",
      "    Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\n",
      "    a JSON document) to a Python object.\n",
      "    \n",
      "    ``object_hook`` is an optional function that will be called with the\n",
      "    result of any object literal decode (a ``dict``). The return value of\n",
      "    ``object_hook`` will be used instead of the ``dict``. This feature\n",
      "    can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n",
      "    \n",
      "    ``object_pairs_hook`` is an optional function that will be called with the\n",
      "    result of any object literal decoded with an ordered list of pairs.  The\n",
      "    return value of ``object_pairs_hook`` will be used instead of the ``dict``.\n",
      "    This feature can be used to implement custom decoders.  If ``object_hook``\n",
      "    is also defined, the ``object_pairs_hook`` takes priority.\n",
      "    \n",
      "    To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``\n",
      "    kwarg; otherwise ``JSONDecoder`` is used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(json.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2023e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ddb54be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Saikiran', 'Age': 23, 'isStudent': False},\n",
       " {'name': 'Savinay', 'Age': 17, 'isStudent': True}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "219e9a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b67e4ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we need to close the connection between the buffer and persistent storage data after reading.\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852e5384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we open text file\n",
    "file = open(\"sample.txt\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3b8335",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd27240a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'name': 'Saikiran', 'Age': 23, 'isStudent': False}, {'name': 'Savinay', 'Age': 17, 'isStudent': True}]\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #Here we get the output as a string format inorder to convert it into list we need to process it explicitly into list .\n",
    " #Whereas in \"json\" we it handles the \"data types or conversions\" etc...\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d584c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we need to use some sort of techniques inorder to tranform our data into our required format or data type like list etc..\n",
    "#It will be a big task for large data which can be done by \"data engineers\" in industries called data transformation.\n",
    "dictdata = list(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "100de6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " '{',\n",
       " \"'\",\n",
       " 'n',\n",
       " 'a',\n",
       " 'm',\n",
       " 'e',\n",
       " \"'\",\n",
       " ':',\n",
       " ' ',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'a',\n",
       " 'i',\n",
       " 'k',\n",
       " 'i',\n",
       " 'r',\n",
       " 'a',\n",
       " 'n',\n",
       " \"'\",\n",
       " ',',\n",
       " ' ',\n",
       " \"'\",\n",
       " 'A',\n",
       " 'g',\n",
       " 'e',\n",
       " \"'\",\n",
       " ':',\n",
       " ' ',\n",
       " '2',\n",
       " '3',\n",
       " ',',\n",
       " ' ',\n",
       " \"'\",\n",
       " 'i',\n",
       " 's',\n",
       " 'S',\n",
       " 't',\n",
       " 'u',\n",
       " 'd',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " \"'\",\n",
       " ':',\n",
       " ' ',\n",
       " 'F',\n",
       " 'a',\n",
       " 'l',\n",
       " 's',\n",
       " 'e',\n",
       " '}',\n",
       " ',',\n",
       " ' ',\n",
       " '{',\n",
       " \"'\",\n",
       " 'n',\n",
       " 'a',\n",
       " 'm',\n",
       " 'e',\n",
       " \"'\",\n",
       " ':',\n",
       " ' ',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'a',\n",
       " 'v',\n",
       " 'i',\n",
       " 'n',\n",
       " 'a',\n",
       " 'y',\n",
       " \"'\",\n",
       " ',',\n",
       " ' ',\n",
       " \"'\",\n",
       " 'A',\n",
       " 'g',\n",
       " 'e',\n",
       " \"'\",\n",
       " ':',\n",
       " ' ',\n",
       " '1',\n",
       " '7',\n",
       " ',',\n",
       " ' ',\n",
       " \"'\",\n",
       " 'i',\n",
       " 's',\n",
       " 'S',\n",
       " 't',\n",
       " 'u',\n",
       " 'd',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " \"'\",\n",
       " ':',\n",
       " ' ',\n",
       " 'T',\n",
       " 'r',\n",
       " 'u',\n",
       " 'e',\n",
       " '}',\n",
       " ']']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It is not a good technique to tranform the above data or string data which is above.we need to write some other technique to perform.\n",
    "#It is a challenging and inefficient and time consuming in ML or datascience so we avoid normal files instead we use \"json\" files and modules.\n",
    "\n",
    "dictdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2919f6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
