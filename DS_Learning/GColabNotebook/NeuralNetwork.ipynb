{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*****NOTE*****:**It's Very very Basic Naive Network,Very Basic ML Neural Network with small Parameters. We will see all advance topics which will used in Neural Networks to make more efficient and powerful using ML Strategies Further.**"
      ],
      "metadata": {
        "id": "dhzIXfnW2l2n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XofjDKuISfPf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "'''\n",
        "Currently, we won't use any Images in this \"Neural Networks\" while coming to \"Convolutions\" we use Images.Till now we will use \"Structural Data\" other than Images Now.\n",
        "So, we can use Pandas and NumPy Mainly we Require these 2.\n",
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"/content/sample_data/california_housing_train.csv\")"
      ],
      "metadata": {
        "id": "ULfeXj539TQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Before going to Building the model we have to make the Data compatibility.We have to check the Data how the Data is and all.\n",
        "#We have to see the Data First.\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "HBpb_xlR9oO5",
        "outputId": "98b8d255-40ee-4528-a6c1-dd9b71f33c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0        -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1        -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2        -114.56     33.69                17.0        720.0           174.0   \n",
              "3        -114.57     33.64                14.0       1501.0           337.0   \n",
              "4        -114.57     33.57                20.0       1454.0           326.0   \n",
              "...          ...       ...                 ...          ...             ...   \n",
              "16995    -124.26     40.58                52.0       2217.0           394.0   \n",
              "16996    -124.27     40.69                36.0       2349.0           528.0   \n",
              "16997    -124.30     41.84                17.0       2677.0           531.0   \n",
              "16998    -124.30     41.80                19.0       2672.0           552.0   \n",
              "16999    -124.35     40.54                52.0       1820.0           300.0   \n",
              "\n",
              "       population  households  median_income  median_house_value  \n",
              "0          1015.0       472.0         1.4936             66900.0  \n",
              "1          1129.0       463.0         1.8200             80100.0  \n",
              "2           333.0       117.0         1.6509             85700.0  \n",
              "3           515.0       226.0         3.1917             73400.0  \n",
              "4           624.0       262.0         1.9250             65500.0  \n",
              "...           ...         ...            ...                 ...  \n",
              "16995       907.0       369.0         2.3571            111400.0  \n",
              "16996      1194.0       465.0         2.5179             79000.0  \n",
              "16997      1244.0       456.0         3.0313            103600.0  \n",
              "16998      1298.0       478.0         1.9797             85800.0  \n",
              "16999       806.0       270.0         3.0147             94600.0  \n",
              "\n",
              "[17000 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51910ed6-37c4-4220-9ed4-0b00a96da529\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16995</th>\n",
              "      <td>-124.26</td>\n",
              "      <td>40.58</td>\n",
              "      <td>52.0</td>\n",
              "      <td>2217.0</td>\n",
              "      <td>394.0</td>\n",
              "      <td>907.0</td>\n",
              "      <td>369.0</td>\n",
              "      <td>2.3571</td>\n",
              "      <td>111400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16996</th>\n",
              "      <td>-124.27</td>\n",
              "      <td>40.69</td>\n",
              "      <td>36.0</td>\n",
              "      <td>2349.0</td>\n",
              "      <td>528.0</td>\n",
              "      <td>1194.0</td>\n",
              "      <td>465.0</td>\n",
              "      <td>2.5179</td>\n",
              "      <td>79000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16997</th>\n",
              "      <td>-124.30</td>\n",
              "      <td>41.84</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2677.0</td>\n",
              "      <td>531.0</td>\n",
              "      <td>1244.0</td>\n",
              "      <td>456.0</td>\n",
              "      <td>3.0313</td>\n",
              "      <td>103600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16998</th>\n",
              "      <td>-124.30</td>\n",
              "      <td>41.80</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2672.0</td>\n",
              "      <td>552.0</td>\n",
              "      <td>1298.0</td>\n",
              "      <td>478.0</td>\n",
              "      <td>1.9797</td>\n",
              "      <td>85800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16999</th>\n",
              "      <td>-124.35</td>\n",
              "      <td>40.54</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1820.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>3.0147</td>\n",
              "      <td>94600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17000 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51910ed6-37c4-4220-9ed4-0b00a96da529')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51910ed6-37c4-4220-9ed4-0b00a96da529 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51910ed6-37c4-4220-9ed4-0b00a96da529');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMMom6M0-P9c",
        "outputId": "64ca7c06-7b91-4e52-dbd8-835a891f2e78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
              "       'total_bedrooms', 'population', 'households', 'median_income',\n",
              "       'median_house_value'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here \"train_data.columns\" is not a List DataType\n",
        "type(train_data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8iU-9CwSoah",
        "outputId": "ce325010-785a-4109-fe29-a0d5b6fd1ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.indexes.base.Index"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#It Stores all the features/columns except label feature/column \n",
        "#Here \"train_data.columns\" is explicitly type casted to List Type.So, we can perform List operations \n",
        "#The remove() method takes a single element as an argument and removes it from the list. If the element doesn't exist, it throws \n",
        "#ValueError: list. remove(x): x not in list exception.\n",
        "X_features = list(train_data.columns)\n",
        "X_features.remove(\"median_house_value\")\n",
        "X_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U9Oiuxo-P58",
        "outputId": "69d49200-1bec-4bfa-ffff-76e3a2cabc78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['longitude',\n",
              " 'latitude',\n",
              " 'housing_median_age',\n",
              " 'total_rooms',\n",
              " 'total_bedrooms',\n",
              " 'population',\n",
              " 'households',\n",
              " 'median_income']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here Im extracting X all the Records with only these above features except label\n",
        "train_data_X = train_data[X_features]\n",
        "train_data_X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Gp1fkWfm-P3B",
        "outputId": "43593988-b3bb-481d-a876-5bd1509ce69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0        -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1        -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2        -114.56     33.69                17.0        720.0           174.0   \n",
              "3        -114.57     33.64                14.0       1501.0           337.0   \n",
              "4        -114.57     33.57                20.0       1454.0           326.0   \n",
              "...          ...       ...                 ...          ...             ...   \n",
              "16995    -124.26     40.58                52.0       2217.0           394.0   \n",
              "16996    -124.27     40.69                36.0       2349.0           528.0   \n",
              "16997    -124.30     41.84                17.0       2677.0           531.0   \n",
              "16998    -124.30     41.80                19.0       2672.0           552.0   \n",
              "16999    -124.35     40.54                52.0       1820.0           300.0   \n",
              "\n",
              "       population  households  median_income  \n",
              "0          1015.0       472.0         1.4936  \n",
              "1          1129.0       463.0         1.8200  \n",
              "2           333.0       117.0         1.6509  \n",
              "3           515.0       226.0         3.1917  \n",
              "4           624.0       262.0         1.9250  \n",
              "...           ...         ...            ...  \n",
              "16995       907.0       369.0         2.3571  \n",
              "16996      1194.0       465.0         2.5179  \n",
              "16997      1244.0       456.0         3.0313  \n",
              "16998      1298.0       478.0         1.9797  \n",
              "16999       806.0       270.0         3.0147  \n",
              "\n",
              "[17000 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e4aa876-3cb9-4ba2-8cce-08d0af7c11b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16995</th>\n",
              "      <td>-124.26</td>\n",
              "      <td>40.58</td>\n",
              "      <td>52.0</td>\n",
              "      <td>2217.0</td>\n",
              "      <td>394.0</td>\n",
              "      <td>907.0</td>\n",
              "      <td>369.0</td>\n",
              "      <td>2.3571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16996</th>\n",
              "      <td>-124.27</td>\n",
              "      <td>40.69</td>\n",
              "      <td>36.0</td>\n",
              "      <td>2349.0</td>\n",
              "      <td>528.0</td>\n",
              "      <td>1194.0</td>\n",
              "      <td>465.0</td>\n",
              "      <td>2.5179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16997</th>\n",
              "      <td>-124.30</td>\n",
              "      <td>41.84</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2677.0</td>\n",
              "      <td>531.0</td>\n",
              "      <td>1244.0</td>\n",
              "      <td>456.0</td>\n",
              "      <td>3.0313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16998</th>\n",
              "      <td>-124.30</td>\n",
              "      <td>41.80</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2672.0</td>\n",
              "      <td>552.0</td>\n",
              "      <td>1298.0</td>\n",
              "      <td>478.0</td>\n",
              "      <td>1.9797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16999</th>\n",
              "      <td>-124.35</td>\n",
              "      <td>40.54</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1820.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>3.0147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17000 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e4aa876-3cb9-4ba2-8cce-08d0af7c11b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e4aa876-3cb9-4ba2-8cce-08d0af7c11b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e4aa876-3cb9-4ba2-8cce-08d0af7c11b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_Y = train_data[\"median_house_value\"]"
      ],
      "metadata": {
        "id": "EUIYKDsA-Pzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we are converting \"train_data_X\" this whole DataFrame into NumPy Array.Bcs, Tensorflow Expects Numpy Arrays OR Tensors\n",
        "#We have \"to_numpy()\" function in the Pandas DataFrame.We need to give \"to_numpy\" to the Pandas DataFrame\n",
        "# \"to_numpy\" is an in-built function in Pandas. then this whole DataFrame will be converted into NumPy Array.\n",
        "#Here \"train_data_X\" is a DataFrame Before converting into \"numpy\" Array\n",
        "train_data_X = train_data_X.to_numpy()\n",
        "#Here \"shape\" represents shape of the \"train_data_X\".17000 is the number of examples and 8 is number of features/columns\n",
        "#Now we are good for the training data for X\n",
        "train_data_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZuuAr_V-Pim",
        "outputId": "f7c7a2a2-13ac-4a9e-ff13-8fd4f38d954d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17000, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we are converting \"train_data_Y\" this whole DataFrame into NumPy Array.Bcs, Tensorflow Expects Numpy Arrays OR Tensors\n",
        "#We have \"to_numpy()\" function in the Pandas DataFrame.We need to give \"to_numpy()\" to the Pandas DataFrame.\n",
        "# \"to_numpy\" is an in-built function in Pandas\n",
        "#Here \"train_data_Y\" is a Series not DataFrame Before converting into \"numpy\" Array \n",
        "train_data_Y = train_data_Y.to_numpy()\n",
        "train_data_Y.shape\n",
        "#Here it is (17000,) it means 17000 examples and 1 feature/column/label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmPEDZKeX9xq",
        "outputId": "fde5856f-1965-4044-9ac2-a9025b5faea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17000,)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***NOTE***: Here Our Input Data is in the form of Image which has (64*64) Resolution ==> 4,096 pixels we can also call each \"pixel\" as one \"feature\".Likewise, we have\n",
        "1024 images with (64*64) Resolution. Each input Image will be treated as an Example it means we have \"1024\" Examples/images with \"4,096\" features/pixels. \n",
        "\n",
        "Q) My Input is (64*64) Resolution ==> 4,096 pixels/features image of 1024 images. then I have 12 nodes of hidden layer 1, 18 nodes of hidden layer 2, 6 nodes of \n",
        "hidden layer 3, 2 nodes of hidden layer 4, 1 node of output layer? \n",
        "\n",
        "Draw Network? --> We need to write/draw the Network then only we can do it furtherly, We can see OR Imagine in our Mind. When we have that in our Mind then only we can write the Program and also Visualize what is happening in Each Layer.If anything Problem occurs OR If Training was not done properly OR If we didn't get accuracy of our Output Propely So, we can Inspect it Ok in which layer the problem occured and where is that problem occured we can able to Inspect it."
      ],
      "metadata": {
        "id": "TdnKXKF89jsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Currently, we won't use any Images in this \"Neural Networks\" while coming to \"Convolutions\" we use Images.Till now we will use \n",
        "\"Structural Data\" other than Images Now.\n",
        "'''\n",
        "'''\n",
        "In this we need to change configuration of nodes and test it this changing configuration to obtain best results is called \"Hyper Parameters\"\n",
        "We discuss this \"Hyper Parameters\" Later in ML Strategies.Here we are taking activation function like \"relu\" for now to inorder to complete \n",
        "Example/programming.We discuss this \"activation\" function Later in ML Strategies.\n",
        "\n",
        "'''\n",
        "# Here \"Dense\" is used for \"number of nodes in Hidden_layer\".\n",
        "#The input for this \"hidden_layer1\" is previous layer which is \"input_layer\"\n",
        "#The input for this \"hidden_layer2\" is previous layer which is \"hidden_layer1\"\n",
        "#The input for this \"hidden_layer3\" is previous layer which is \"hidden_layer2\"\n",
        "#The input for this \"hidden_layer4\" is previous layer which is \"hidden_layer3\"\n",
        "#The input for this \"output_layer\" is previous layer which is \"hidden_layer4\"\n",
        "#Currently, the number of examples are not concerned for us now.We take only the features/nodes.So, it is in 1D\n",
        "input_layer = tf.keras.Input(shape=(8,)) #Here \"8\" is number of features\n",
        "#One more thing we have to Normalize the Input here.Normalization layer should be there\n",
        "normalization_layer = tf.keras.layers.Normalization()(input_layer)\n",
        "hidden_layer1 = tf.keras.layers.Dense(15,activation=\"relu\")(normalization_layer)  \n",
        "hidden_layer2 = tf.keras.layers.Dense(12,activation=\"relu\")(hidden_layer1)\n",
        "hidden_layer3 = tf.keras.layers.Dense(6,activation=\"relu\")(hidden_layer2)  \n",
        "hidden_layer4 = tf.keras.layers.Dense(2,activation=\"relu\")(hidden_layer3)  \n",
        "output_layer = tf.keras.layers.Dense(1,activation=\"relu\")(hidden_layer4)  \n",
        "# Here \"keras\" is a Sub module in that \"models\" is a package in that \"Model\" is a class in this class we are giving \"input & output\" Layer \n",
        "model = tf.keras.models.Model(input_layer,output_layer)"
      ],
      "metadata": {
        "id": "tDnup4BuaP1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "#In Below the Output shape of each layer is w.r.t Parameters \"W,b\" in 1D without considering Examples OR w.r.t 1 Example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_QCxu66534c",
        "outputId": "579ce303-8e14-4615-9554-d35362689f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 8)]               0         \n",
            "                                                                 \n",
            " normalization_1 (Normalizat  (None, 8)                17        \n",
            " ion)                                                            \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 15)                135       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 12)                192       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 6)                 78        \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 2)                 14        \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 439\n",
            "Trainable params: 422\n",
            "Non-trainable params: 17\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"mse\",metrics=\"mse\")"
      ],
      "metadata": {
        "id": "BV6tum7Z5-42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data_X,train_data_Y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdS9ptloIUxu",
        "outputId": "8bde8d38-958c-4885-c4b0-cd1aae79b53c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "532/532 [==============================] - 2s 2ms/step - loss: 37836242944.0000 - mse: 37836242944.0000\n",
            "Epoch 2/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 26253715456.0000 - mse: 26253715456.0000\n",
            "Epoch 3/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 24741402624.0000 - mse: 24741402624.0000\n",
            "Epoch 4/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 22587856896.0000 - mse: 22587856896.0000\n",
            "Epoch 5/100\n",
            "532/532 [==============================] - 1s 3ms/step - loss: 19019407360.0000 - mse: 19019407360.0000\n",
            "Epoch 6/100\n",
            "532/532 [==============================] - 1s 3ms/step - loss: 14237185024.0000 - mse: 14237185024.0000\n",
            "Epoch 7/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 11763154944.0000 - mse: 11763154944.0000\n",
            "Epoch 8/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 11311997952.0000 - mse: 11311997952.0000\n",
            "Epoch 9/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 11138513920.0000 - mse: 11138513920.0000\n",
            "Epoch 10/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 11011881984.0000 - mse: 11011881984.0000\n",
            "Epoch 11/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 10886995968.0000 - mse: 10886995968.0000\n",
            "Epoch 12/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 10770811904.0000 - mse: 10770811904.0000\n",
            "Epoch 13/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 10638546944.0000 - mse: 10638546944.0000\n",
            "Epoch 14/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 10519515136.0000 - mse: 10519515136.0000\n",
            "Epoch 15/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 10383305728.0000 - mse: 10383305728.0000\n",
            "Epoch 16/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 10223905792.0000 - mse: 10223905792.0000\n",
            "Epoch 17/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 10036795392.0000 - mse: 10036795392.0000\n",
            "Epoch 18/100\n",
            "532/532 [==============================] - 1s 3ms/step - loss: 9822571520.0000 - mse: 9822571520.0000\n",
            "Epoch 19/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 9596597248.0000 - mse: 9596597248.0000\n",
            "Epoch 20/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 9340281856.0000 - mse: 9340281856.0000\n",
            "Epoch 21/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 9083290624.0000 - mse: 9083290624.0000\n",
            "Epoch 22/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 8815428608.0000 - mse: 8815428608.0000\n",
            "Epoch 23/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 8601286656.0000 - mse: 8601286656.0000\n",
            "Epoch 24/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 8404739584.0000 - mse: 8404739584.0000\n",
            "Epoch 25/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 8224955392.0000 - mse: 8224955392.0000\n",
            "Epoch 26/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 8063789056.0000 - mse: 8063789056.0000\n",
            "Epoch 27/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 7927649280.0000 - mse: 7927649280.0000\n",
            "Epoch 28/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 7796270592.0000 - mse: 7796270592.0000\n",
            "Epoch 29/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 7675908608.0000 - mse: 7675908608.0000\n",
            "Epoch 30/100\n",
            "532/532 [==============================] - 1s 3ms/step - loss: 7575385600.0000 - mse: 7575385600.0000\n",
            "Epoch 31/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 7490660864.0000 - mse: 7490660864.0000\n",
            "Epoch 32/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 7381719040.0000 - mse: 7381719040.0000\n",
            "Epoch 33/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 7290637312.0000 - mse: 7290637312.0000\n",
            "Epoch 34/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 7187692544.0000 - mse: 7187692544.0000\n",
            "Epoch 35/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 7091334656.0000 - mse: 7091334656.0000\n",
            "Epoch 36/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 6999186944.0000 - mse: 6999186944.0000\n",
            "Epoch 37/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 6886117376.0000 - mse: 6886117376.0000\n",
            "Epoch 38/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 6824643072.0000 - mse: 6824643072.0000\n",
            "Epoch 39/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 6716865024.0000 - mse: 6716865024.0000\n",
            "Epoch 40/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 6639365120.0000 - mse: 6639365120.0000\n",
            "Epoch 41/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 6555511296.0000 - mse: 6555511296.0000\n",
            "Epoch 42/100\n",
            "532/532 [==============================] - 1s 3ms/step - loss: 6477471232.0000 - mse: 6477471232.0000\n",
            "Epoch 43/100\n",
            "532/532 [==============================] - 1s 3ms/step - loss: 6414027776.0000 - mse: 6414027776.0000\n",
            "Epoch 44/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 6332346880.0000 - mse: 6332346880.0000\n",
            "Epoch 45/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 6287345152.0000 - mse: 6287345152.0000\n",
            "Epoch 46/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 6216266240.0000 - mse: 6216266240.0000\n",
            "Epoch 47/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 6139514880.0000 - mse: 6139514880.0000\n",
            "Epoch 48/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 6082957824.0000 - mse: 6082957824.0000\n",
            "Epoch 49/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 6038093824.0000 - mse: 6038093824.0000\n",
            "Epoch 50/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5961717248.0000 - mse: 5961717248.0000\n",
            "Epoch 51/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5908061696.0000 - mse: 5908061696.0000\n",
            "Epoch 52/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5855427584.0000 - mse: 5855427584.0000\n",
            "Epoch 53/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5804668928.0000 - mse: 5804668928.0000\n",
            "Epoch 54/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5753991680.0000 - mse: 5753991680.0000\n",
            "Epoch 55/100\n",
            "532/532 [==============================] - 1s 3ms/step - loss: 5702502400.0000 - mse: 5702502400.0000\n",
            "Epoch 56/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5660783616.0000 - mse: 5660783616.0000\n",
            "Epoch 57/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5589282816.0000 - mse: 5589282816.0000\n",
            "Epoch 58/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5557388800.0000 - mse: 5557388800.0000\n",
            "Epoch 59/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5493688320.0000 - mse: 5493688320.0000\n",
            "Epoch 60/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5443993088.0000 - mse: 5443993088.0000\n",
            "Epoch 61/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5416198144.0000 - mse: 5416198144.0000\n",
            "Epoch 62/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5363140608.0000 - mse: 5363140608.0000\n",
            "Epoch 63/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5323862016.0000 - mse: 5323862016.0000\n",
            "Epoch 64/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5273593344.0000 - mse: 5273593344.0000\n",
            "Epoch 65/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5235567616.0000 - mse: 5235567616.0000\n",
            "Epoch 66/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5170170368.0000 - mse: 5170170368.0000\n",
            "Epoch 67/100\n",
            "532/532 [==============================] - 1s 3ms/step - loss: 5111475712.0000 - mse: 5111475712.0000\n",
            "Epoch 68/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5073377792.0000 - mse: 5073377792.0000\n",
            "Epoch 69/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5038902272.0000 - mse: 5038902272.0000\n",
            "Epoch 70/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 5005184512.0000 - mse: 5005184512.0000\n",
            "Epoch 71/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4961115136.0000 - mse: 4961115136.0000\n",
            "Epoch 72/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4936961536.0000 - mse: 4936961536.0000\n",
            "Epoch 73/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4903939072.0000 - mse: 4903939072.0000\n",
            "Epoch 74/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4848002560.0000 - mse: 4848002560.0000\n",
            "Epoch 75/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4847143936.0000 - mse: 4847143936.0000\n",
            "Epoch 76/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4814952448.0000 - mse: 4814952448.0000\n",
            "Epoch 77/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4781414912.0000 - mse: 4781414912.0000\n",
            "Epoch 78/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4768596992.0000 - mse: 4768596992.0000\n",
            "Epoch 79/100\n",
            "532/532 [==============================] - 1s 3ms/step - loss: 4759309312.0000 - mse: 4759309312.0000\n",
            "Epoch 80/100\n",
            "532/532 [==============================] - 1s 3ms/step - loss: 4732830720.0000 - mse: 4732830720.0000\n",
            "Epoch 81/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4703474176.0000 - mse: 4703474176.0000\n",
            "Epoch 82/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4685574656.0000 - mse: 4685574656.0000\n",
            "Epoch 83/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4737818624.0000 - mse: 4737818624.0000\n",
            "Epoch 84/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4715979264.0000 - mse: 4715979264.0000\n",
            "Epoch 85/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4704607232.0000 - mse: 4704607232.0000\n",
            "Epoch 86/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4660190208.0000 - mse: 4660190208.0000\n",
            "Epoch 87/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4648393728.0000 - mse: 4648393728.0000\n",
            "Epoch 88/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4634854400.0000 - mse: 4634854400.0000\n",
            "Epoch 89/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4626382848.0000 - mse: 4626382848.0000\n",
            "Epoch 90/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4641001984.0000 - mse: 4641001984.0000\n",
            "Epoch 91/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4629100544.0000 - mse: 4629100544.0000\n",
            "Epoch 92/100\n",
            "532/532 [==============================] - 1s 3ms/step - loss: 4670827520.0000 - mse: 4670827520.0000\n",
            "Epoch 93/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4643651584.0000 - mse: 4643651584.0000\n",
            "Epoch 94/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4616002048.0000 - mse: 4616002048.0000\n",
            "Epoch 95/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4608548352.0000 - mse: 4608548352.0000\n",
            "Epoch 96/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4625519104.0000 - mse: 4625519104.0000\n",
            "Epoch 97/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4636102656.0000 - mse: 4636102656.0000\n",
            "Epoch 98/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4637962752.0000 - mse: 4637962752.0000\n",
            "Epoch 99/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4605157888.0000 - mse: 4605157888.0000\n",
            "Epoch 100/100\n",
            "532/532 [==============================] - 1s 2ms/step - loss: 4614469632.0000 - mse: 4614469632.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f61d13b1460>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ENow, we have the model with Us then we can save the model with the \"model.save()\" with naming \"model.h5\" \n",
        "#Basically, the \"h5\" is the format of this we need to save.then it will be saved and we can download it and use for inferencing,deploying \n",
        "model.save(\"model.h5\") "
      ],
      "metadata": {
        "id": "Et_LLPfGIf62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UBjF5zS267hO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}